# Nexus Docker Environment Configuration
# Copy this file to .env and customize as needed
# cp .env.example .env

# ============================================
# Port Configuration
# ============================================

# Frontend port (where you access the web UI)
FRONTEND_PORT=3000

# Backend port (API server - usually don't need to change)
BACKEND_PORT=8000

# ============================================
# Ollama Configuration (Host System)
# ============================================

# Ollama host - use host.docker.internal to access host's Ollama
# If Ollama runs on a different machine, change to that IP address
OLLAMA_HOST=host.docker.internal

# Ollama port (default is 11434)
OLLAMA_PORT=11434

# AI Model to use (must be pulled first with 'ollama pull <model>')
# Recommended models:
#   - gpt-oss:20b (default, high quality)
#   - llama3.1:8b (faster, lighter)
#   - mistral:7b (good balance)
AI_MODEL=gpt-oss:20b

# ============================================
# Application Configuration
# ============================================

# Logging level (debug, info, warning, error)
LOG_LEVEL=info

# ============================================
# Future Configuration (Placeholder)
# ============================================

# Database (not yet implemented)
# DB_HOST=localhost
# DB_PORT=5432

# Security (not yet implemented)
# JWT_SECRET=your-secret-key-here
# SESSION_TIMEOUT=3600
